{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of TF-IDF\n",
    "\n",
    "TF-IDF (short for term frequency–inverse document frequency) is a numerical statistic that is intended to reflect how important a word is to a document in a corpus.\n",
    "\n",
    "The tf–idf value increases proportionally to the number of times a word appears in the document and is offset by the number of documents in the corpus that contain the word.\n",
    "\n",
    "So, words that are common in every document, such as \"this\", \"what\", and \"if\", rank low even though they may appear many times, since they don’t mean much to that document in particular. However, if the word \"Bug\" appears many times in a document, while not appearing many times in others, it probably means that it’s very relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest Data\n",
    "\n",
    "* The tickets that were used to train model (created during the Code Sprint): \"sample_data.json\".\n",
    "* The number of tickets used to train the model: 31794 tickets.\n",
    "* No filtering was employed. Only the ticket text (tittle and body) were used.\n",
    "\n",
    "**Data used for training:** all tickets (title and body text data) from \"sample_data.json\"\n",
    "**Data used for keyword extraction:** first 500 tickets (only title and body text data) from \"sample_data.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get data for training\"\"\"\n",
    "\n",
    "with open(\"data/sample_data1.json\") as f:\n",
    "  data = json.load(f)\n",
    "\n",
    "tickets = {}\n",
    "tickets = data['tickets']\n",
    "\n",
    "with open('data/ticket_data.json', 'w') as json_file:\n",
    "  json.dump(tickets, json_file)\n",
    "\n",
    "\n",
    "\"\"\"Get first 500 tickets from all of the data for the keyword extraction\"\"\"\n",
    "sample_tickets = []\n",
    "sample_tickets =  tickets[0:500]\n",
    "\n",
    "with open('data/sample_ticket_data.json', 'w') as json_file:\n",
    "  json.dump(sample_tickets, json_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Feature Engineering steps\n",
    "\n",
    "Inlcude the series of data cleaning steps that are included in your workflow\n",
    "\n",
    "- stopword removal strategy\n",
    "- tokenization/stemming strategy\n",
    "- normalization\n",
    "\n",
    "Steps:\n",
    "1. read json into a dataframe\n",
    "2. make all text lowercase\n",
    "3. Remove all tags\n",
    "4. Remove special characters and digits\n",
    "5. Ignore words that appear in 85% of documents\n",
    "6. Eliminate stopwords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(text):\n",
    "    \n",
    "    # lowercase\n",
    "    text=text.lower()\n",
    "    \n",
    "    #remove tags\n",
    "    text=re.sub(\"</?.*?>\",\" <> \",text)\n",
    "    \n",
    "    # remove special characters and digits\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# print schema\\nprint(\"Schema:\\n\\n\",df_idf.dtypes)\\nprint(\"Number of questions,columns=\",df_idf.shape)\\n\\n#show the first \\'text\\'\\ndf_idf[\\'text\\'][0]\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read json into a dataframe\n",
    "df_idf = pd.read_json(\"data/ticket_data.json\")\n",
    "\n",
    "df_idf['text'] = df_idf['title'] + df_idf['content']\n",
    "df_idf['text'] = df_idf['text'].apply(lambda x:pre_process(x))\n",
    "\n",
    "\"\"\"\n",
    "# print schema\n",
    "print(\"Schema:\\n\\n\",df_idf.dtypes)\n",
    "print(\"Number of questions,columns=\",df_idf.shape)\n",
    "\n",
    "#show the first 'text'\n",
    "df_idf['text'][0]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test docs into a dataframe and concatenate title and body\n",
    "df_test=pd.read_json(\"data/sample_ticket_data.json\")\n",
    "df_test['text'] = df_test['title'] + df_test['content']\n",
    "df_test['text'] =df_test['text'].apply(lambda x:pre_process(x))\n",
    "\n",
    "# get test docs into a list\n",
    "docs_test=df_test['text'].tolist()\n",
    "docs_title=df_test['title'].tolist()\n",
    "docs_body=df_test['content'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tag lexicon definition description\n",
    "\n",
    "The next step is to compute the tf-idf value for a given document in our test set by invoking tfidf_transformer.transform(...). This generates a vector of tf-idf scores. Next, we sort the words in the vector in descending order of tf-idf values and then iterate over to extract the top-n items with the corresponding feature names, In the example below, we are extracting keywords for the first document in our test set.\n",
    "\n",
    "The sort_coo(...) method essentially sorts the values in the vector while preserving the column index. Once you have the column index then its really easy to look-up the corresponding word value as you would see in extract_topn_from_vector(...) where we do feature_vals.append(feature_names[idx])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the text column \n",
    "docs=df_idf['text'].tolist()\n",
    "\n",
    "#create a vocabulary of words, \n",
    "#ignore words that appear in 85% of documents\n",
    "#eliminate stop words\n",
    "cv=CountVectorizer(max_df=0.50,stop_words=stopwords.words('english'), min_df=1)\n",
    "word_count_vector=cv.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have 31794 tickets with 45336 unique words in our dataset minus stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31794, 45335)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Inverse Document Frequency (IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.57530485,  9.57530485, 10.26845204, ..., 10.67391714,\n",
       "       10.67391714, 10.67391714])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_transformer.fit(word_count_vector)\n",
    "\n",
    "tfidf_transformer.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "\n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    "\n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "\n",
    "    for idx, score in sorted_items:\n",
    "        fname = feature_names[idx]\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    "\n",
    "    #create a tuples of feature,score\n",
    "    #results = zip(feature_vals,score_vals)\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you only needs to do this once\n",
    "feature_names=cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the common code into several methods\n",
    "def get_keywords(idx):\n",
    "\n",
    "    #generate tf-idf for the given document\n",
    "    tf_idf_vector=tfidf_transformer.transform(cv.transform([docs_test[idx]]))\n",
    "\n",
    "    #sort the tf-idf vectors by descending order of scores\n",
    "    sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    "\n",
    "    #extract only the top n; n here is 10\n",
    "    keywords=extract_topn_from_vector(feature_names,sorted_items,10)\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "def print_results(idx,keywords):\n",
    "    # now print the results\n",
    "    print(\"\\n=====Title=====\")\n",
    "    print(docs_title[idx])\n",
    "    print(\"\\n=====Body=====\")\n",
    "    print(docs_body[idx])\n",
    "    print(\"\\n===Keywords===\")\n",
    "    for k in keywords:\n",
    "        print(k,keywords[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====Title=====\n",
      "Firefox crashes\n",
      "\n",
      "=====Body=====\n",
      "<p>I am having crashes in FF 15.0.1 when I use Outlook Web Access. It usually happens when I change folders or have an item open and go back to the main OWA screen. This is happening many times a day and I always submit a crash report. I have put the latest crash report ID below. Please help as I rely on OWA for my work email.\n",
      "</p>\n",
      "\n",
      "===Keywords===\n",
      "owa 0.539\n",
      "report 0.299\n",
      "crash 0.258\n",
      "rely 0.23\n",
      "crashes 0.229\n",
      "submit 0.187\n",
      "outlook 0.182\n",
      "item 0.171\n",
      "main 0.157\n",
      "folders 0.157\n"
     ]
    }
   ],
   "source": [
    "idx=220\n",
    "keywords=get_keywords(idx)\n",
    "print_results(idx,keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier/Annontator Training step\n",
    "\n",
    "Describe the model and the model training step\n",
    "\n",
    "- Include a description the feature space used\n",
    "- Include a description of the selected classification or annotation model\n",
    "- Describe the training process and expected runtime for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'code that executes model training step'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"code that executes model training step\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier/Annotator Testing step\n",
    "\n",
    "Describe the testing of the trained model's performace against a defined test set.\n",
    "\n",
    "- Include the raw performance\n",
    "- Include the source of ground truth for the evaluation\n",
    "- Include figures for FP/FN/ROC type metrics describing the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'code that executes the model testing step'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"code that executes the model testing step\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "Sumamrize the model performance and findings related to specific misclassified items also a breif description of the findings as they correpsonde to generalizability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
